{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8b5954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gatupov/anaconda3/envs/ml/lib/python3.7/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import torch\n",
    "import torch.utils.data as D\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import albumentations as A\n",
    "from torchvision import transforms as T\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch import Unet, FPN\n",
    "import time\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6cc234",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d314d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'coco_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e014dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppr(x, nx): # просто форматированный вывод переменной\n",
    "    print(nx + ': ' + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879beb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Извлекаем картинки\n",
    "\n",
    "# num_of_id = 1\n",
    "# img = io.imread(DATA_DIR + f'img_{num_of_id}')\n",
    "# mask = io.imread(DATA_DIR + f'mask_{num_of_id}')\n",
    "# mask = mask[:,:,0]/255\n",
    "# # visualisation\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "# plt.axis('off')\n",
    "# plt.imshow(mask)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03faef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(shape, window=256, min_overlap=32):\n",
    "    \"\"\"\n",
    "        Return Array of size (N,4), where N - number of tiles,\n",
    "        2nd axis represente slices: x1,x2,y1,y2 \n",
    "    \"\"\"\n",
    "    x, y = shape\n",
    "    nx = x // (window - min_overlap) + 1\n",
    "    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n",
    "    x1[-1] = x - window\n",
    "    x2 = (x1 + window).clip(0, x)\n",
    "    ny = y // (window - min_overlap) + 1\n",
    "    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n",
    "    y1[-1] = y - window\n",
    "    y2 = (y1 + window).clip(0, y)\n",
    "    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n",
    "    \n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            slices[i,j] = x1[i], x2[i], y1[j], y2[j]    \n",
    "    return slices.reshape(nx*ny,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "476d9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW=128\n",
    "MIN_OVERLAP=16\n",
    "NEW_SIZE=128\n",
    "NUMBER_OF_SAMPLES = 1480\n",
    "\n",
    "trfm = A.Compose([\n",
    "    A.Resize(NEW_SIZE,NEW_SIZE),\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "#     A.ColorJitter (brightness=0.07, contrast=0.07,\n",
    "#                    saturation=0.1, hue=0.1, always_apply=False, p=0.3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c13b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoCoDataset(D.Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform,\n",
    "                 window=256, overlap=32, threshold=0.25, number_of_samples = NUMBER_OF_SAMPLES):  \n",
    "        self.path = root_dir  # папка\n",
    "        self.overlap = overlap  # перекрытие плиток\n",
    "        self.window = window  # размер окна\n",
    "        self.transform = transform   # трансформации изображения (как минимум изменение размеров)\n",
    "        self.threshold = threshold  # для отбрасывания плиток без кошки\n",
    "        self.build_slices()\n",
    "        self.len = len(self.slices)\n",
    "        self.as_tensor = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.625, 0.448, 0.688],\n",
    "                        [0.131, 0.177, 0.101]),\n",
    "        ])\n",
    "    def build_slices(self):\n",
    "        self.masks = [] # массив с масками. [id_of_image][h][w]\n",
    "        self.slices = [] # массив со срезами [id_of_slice][4] (x1,x2,y1,y2)\n",
    "        for num_of_id in range(NUMBER_OF_SAMPLES):\n",
    "            mask = io.imread(self.path + f'mask_{num_of_id}')\n",
    "            mask = mask[:,:,0]/255 # полная нормированная маска (числа [0, 1])\n",
    "            self.masks.append(mask)\n",
    "\n",
    "            slices = make_grid(mask.shape, window=self.window,\n",
    "                                min_overlap=self.overlap) \n",
    "            for slc in slices:\n",
    "                x1,x2,y1,y2 = slc\n",
    "                if mask[x1:x2,y1:y2].sum() > self.threshold:\n",
    "                    self.slices.append([num_of_id,x1,x2,y1,y2])\n",
    "                        \n",
    "    # get data operation\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # index - это индекс среза, то есть \"номер плитки\"!\n",
    "        \n",
    "        num_of_id = self.slices[index][0]\n",
    "        x1,x2,y1,y2 = self.slices[index][1:]\n",
    "        img = io.imread(self.path + f'img_{num_of_id}')\n",
    "        image = img[x1:x2,y1:y2].copy()       \n",
    "        mask = self.masks[num_of_id][x1:x2,y1:y2]       \n",
    "        augments = self.transform(image=image, mask=mask)\n",
    "        #return image, mask\n",
    "        return self.as_tensor(augments['image']), augments['mask'][None] #??????????????????\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len\n",
    "    \n",
    "train = CoCoDataset(DATA_DIR, window=WINDOW, overlap=MIN_OVERLAP, transform=trfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb270188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, mask = train[0]\n",
    "# print(img.shape)\n",
    "# print(mask.shape)\n",
    "# len(train.slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0fa8bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем валидационный набор\n",
    "valid_idx, train_idx = [], []\n",
    "for i in range(NUMBER_OF_SAMPLES):\n",
    "    if train.slices[i][0] % 4 == 0: # отбор всех плиток, относящейся к каждой 4-ой картинке в валидационный датасет\n",
    "        valid_idx.append(i)\n",
    "    else:\n",
    "        train_idx.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d745600",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 1\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "759beec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Определяем загрузчики\n",
    "train_ds = D.Subset(train, train_idx)\n",
    "valid_ds = D.Subset(train, valid_idx)\n",
    "\n",
    "loader = D.DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "vloader = D.DataLoader(\n",
    "    valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ff57f4",
   "metadata": {},
   "source": [
    "# NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a55121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    ENCODER = 'se_resnext50_32x4d'\n",
    "    ENCODER_WEIGHTS = 'imagenet'\n",
    "    CLASSES_NUMBER = 1\n",
    "    ACTIVATION = 'sigmoid'  # could be None for logits or 'softmax2d' for multicalss segmentation\n",
    "\n",
    "    # create segmentation model with pretrained encoder\n",
    "    model = smp.Unet(\n",
    "        encoder_name=ENCODER,\n",
    "        encoder_weights=ENCODER_WEIGHTS,\n",
    "        classes=CLASSES_NUMBER,\n",
    "        activation=ACTIVATION,\n",
    "    )\n",
    "\n",
    "    preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11bf4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(model, loader, loss_fn):\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    for image, target in loader:\n",
    "        image, target = image.to(DEVICE), target.float().to(DEVICE)\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, target)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    return np.array(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20116c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "model.to(DEVICE)\n",
    "print('Successfully sent to GPU')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr=1e-4, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd05dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS function\n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1., dims=(-2,-1)):\n",
    "\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.dims = dims\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "\n",
    "        tp = (x * y).sum(self.dims)\n",
    "        fp = (x * (1 - y)).sum(self.dims)\n",
    "        fn = ((1 - x) * y).sum(self.dims)\n",
    "        \n",
    "        dc = (2 * tp + self.smooth) / (2 * tp + fp + fn + self.smooth)\n",
    "        dc = dc.mean()\n",
    "\n",
    "        return 1 - dc\n",
    "    \n",
    "class SoftDiceBCEWithLogitsLoss:\n",
    "    def __init__():\n",
    "        self.bce_fn = nn.BCEWithLogitsLoss()\n",
    "        self.dice_fn = SoftDiceLoss()\n",
    "    \n",
    "    def __call__(y_pred, y_true):\n",
    "        self.bce = bce_fn(y_pred, y_true)\n",
    "        self.dice = dice_fn(y_pred.sigmoid(), y_true)\n",
    "        return 0.8*bce+ 0.2*dice\n",
    "    \n",
    "    \n",
    "bce_fn = nn.BCEWithLogitsLoss()\n",
    "dice_fn = SoftDiceLoss()\n",
    "\n",
    "def loss_fn(y_pred, y_true):\n",
    "    bce = bce_fn(y_pred, y_true)\n",
    "    dice = dice_fn(y_pred.sigmoid(), y_true)\n",
    "    return 0.8*bce+ 0.2*dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0e1eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Table for results\n",
    "header = r'''\n",
    "        Train | Valid\n",
    "Epoch |  Loss |  Loss | Time, m\n",
    "'''\n",
    "#          Epoch         metrics            time\n",
    "raw_line = '{:6d}' + '\\u2502{:7.3f}'*2 + '\\u2502{:6.2f}'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5929ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Train | Valid\n",
      "Epoch |  Loss |  Loss | Time, m\n",
      "\n",
      "1 2 \n",
      "     1│  0.725│  0.709│  0.40\n"
     ]
    }
   ],
   "source": [
    "print(header)\n",
    "# train\n",
    "for epoch in range(1, EPOCHES+1):\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    n_iter = 0\n",
    "    for image, target in loader:\n",
    "        image, target = image.to(DEVICE), target.float().to(DEVICE)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        #ppr(output.shape,'shape_model:')\n",
    "        #ppr(target.shape,'shape_target:')\n",
    "        #ppr(output[0][0],'output:')\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_iter += 1\n",
    "        if n_iter % 10 ==0:\n",
    "            print(n_iter//10, end=' ')\n",
    "            \n",
    "        ################################################################\n",
    "        #TODO: Убрать после теста!\n",
    "        losses.append(loss.item())\n",
    "        if n_iter //10 == 2:\n",
    "            break\n",
    "        ######################################################################\n",
    "#         writer.add_scalar('Loss/train', loss.item(), n_iter)\n",
    "    vloss = validation(model, vloader, loss_fn)\n",
    "#     writer.add_scalar('Loss/val', vloss, n_iter)\n",
    "    print()\n",
    "    print(raw_line.format(epoch, np.array(losses).mean(), vloss,\n",
    "                              (time.time()-start_time)/60**1))\n",
    "    losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d059522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "### Сохранение модели\n",
    "DIR_OF_MODEL = 'CatPytorchModel'\n",
    "name_model = 'base_model'\n",
    "if not os.path.exists(DIR_OF_MODEL):\n",
    "    os.mkdir(DIR_OF_MODEL)\n",
    "if os.path.exists(DIR_OF_MODEL + '/' + name_model):\n",
    "    os.remove(DIR_OF_MODEL + '/' + name_model)\n",
    "\n",
    "torch.save(model.state_dict(), DIR_OF_MODEL + '/' + name_model)\n",
    "print('Saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
